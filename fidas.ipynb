{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e67328d4",
   "metadata": {},
   "source": [
    "0  status bit sensor flow  \n",
    "1  status bit coincidence  \n",
    "2  status bit suction pumps  \n",
    "3  status bit weather station  \n",
    "4  status bit IADS  \n",
    "5  status bit estimated raw channel deviation  \n",
    "6  status bit LED temperature  \n",
    "7  status bit operating modus  \n",
    "  \n",
    "20  velocity [m/s]  \n",
    "21  coincidence [%]  \n",
    "22  modus  \n",
    "23  suction pump output [%]  \n",
    "24  IADS temperature (Fidas) evaporation unit (UF-CPC), sensor #1 (Promo) [°C]  \n",
    "25  estimated raw channel deviation [channels]  \n",
    "26  LED temperature [°C]  \n",
    "27  flow rate [l/min]  \n",
    "28  Cn for UF-CPC [P/cm³] (count and nephelometer modus)  \n",
    "29  x50 droplet diameter (UF-CPC) [μm]  \n",
    "30  temperature of condensation unit (UF-CPC), sensor #2 (Promo) [°C]\n",
    "40  temperature [°C]  \n",
    "41  relative humidity [%]  \n",
    "42  wind speed [km/h]  \n",
    "43  wind direction [°]  \n",
    "44  precipitation intensity [l/m²/h]  \n",
    "45  precipitation type \n",
    "46  temperature dew point [°C]  \n",
    "47  air pressure [hPa]  \n",
    "48  wind signal quality [%]  \n",
    "  \n",
    "Fidas/Promo only: \n",
    "52 PM2.5 [mg/m³] – 1 s average \n",
    "53 PM10 [mg/m³] – 1 s average \n",
    "54 PM1 [mg/m³] – 10 s average \n",
    "55 PM2.5 [mg/m³] – 10 s average \n",
    "56 PM10 [mg/m³] – 10 s average \n",
    "57 PMtot [mg/m³] – 10 s average \n",
    "58 PM2.5 [mg/m³] – 60 s average \n",
    "59 PM10 [mg/m³] – 60 s average \n",
    "60  Cn [P/cm³] (PM averaging interval, default: 900s) \n",
    "61  PM1 [mg/m³]  \n",
    "62  PM2.5 [mg/m³]  \n",
    "63  PM4 [mg/m³]  \n",
    "64  PM10 [mg/m³]  \n",
    "65  PMtotal [mg/m³]  \n",
    "66-109  further PM values [mg/m³] (different algorithms)  \n",
    "110ff  ΔCn [P/cm³] size distribution with size intervals as shown by the device under \n",
    "Expert User Mode / Particle Size Distribution / Table (10 s average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667b4e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening on 192.168.2.129:56790 every 60 seconds...\n",
      "Error during UDP read: [WinError 10040] A message sent on a datagram socket was larger than the internal message buffer or some other network limit, or the buffer used to receive a datagram into was smaller than the datagram itself\n",
      "[2025-04-25 17:13:22.809333] Collected median, running summary count: 1\n",
      "Failed to parse record: invalid literal for int() with base 10: '2F6082'\n",
      "Error during UDP read: [WinError 10040] A message sent on a datagram socket was larger than the internal message buffer or some other network limit, or the buffer used to receive a datagram into was smaller than the datagram itself\n",
      "Failed to parse record: invalid literal for int() with base 10: '2F6082'\n",
      "Error during UDP read: [WinError 10040] A message sent on a datagram socket was larger than the internal message buffer or some other network limit, or the buffer used to receive a datagram into was smaller than the datagram itself\n",
      "Stopped by user.\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "import polars as pl\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import schedule\n",
    "import time\n",
    "from typing import Any\n",
    "\n",
    "# --- CONFIGURABLE PARAMETERS ---\n",
    "BASE_DIR = \"data/fidas\"\n",
    "INTERVAL_SECONDS = 60  # how often to compute a median\n",
    "BUFFER_SIZE = 1024\n",
    "LOCAL_IP = \"192.168.2.129\"\n",
    "LOCAL_PORT = 56790\n",
    "\n",
    "# --- GLOBALS ---\n",
    "sock = None\n",
    "buffer = \"\"\n",
    "summary_df = pl.DataFrame()\n",
    "current_hour = datetime.datetime.now(datetime.timezone.utc).replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "# --- CORE FUNCTIONS ---\n",
    "\n",
    "def parse_udp_record(record: str) -> \"dict[str, Any]\":\n",
    "    try:\n",
    "        id_part, rest = record.split('<', 1)\n",
    "        data_part, checksum = rest.split('>', 1)\n",
    "        parsed = {\"id\": int(id_part.strip()), \"checksum\": checksum.strip()}\n",
    "        if data_part.startswith(\"sendVal\"):\n",
    "            data_part = data_part[len(\"sendVal\"):].strip()\n",
    "        for pair in data_part.split(';'):\n",
    "            if '=' in pair:\n",
    "                k, v = pair.split('=', 1)\n",
    "                key = f\"val_{int(k.strip())}\"\n",
    "                try:\n",
    "                    val = float(v.strip())\n",
    "                except ValueError:\n",
    "                    val = float('nan')\n",
    "                parsed[key] = val\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse record: {e}\")\n",
    "        return {}\n",
    "\n",
    "def ensure_output_path(dt: datetime.datetime) -> Path:\n",
    "    folder = Path(BASE_DIR) / f\"{dt.year:04d}\" / f\"{dt.month:02d}\" / f\"{dt.day:02d}\"\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"fidas-{dt.year:04d}{dt.month:02d}{dt.day:02d}{dt.hour:02d}.parquet\"\n",
    "    return folder / filename\n",
    "\n",
    "def read_udp_for_duration(seconds: int) -> \"list[dict[str, Any]]\":\n",
    "    global buffer\n",
    "    records = []\n",
    "    start = time.time()\n",
    "    sock.settimeout(seconds)\n",
    "    try:\n",
    "        while time.time() - start < seconds:\n",
    "            remaining = seconds - (time.time() - start)\n",
    "            if remaining <= 0:\n",
    "                break\n",
    "            try:\n",
    "                data, _ = sock.recvfrom(BUFFER_SIZE)\n",
    "                buffer += data.decode('ascii', errors='ignore')\n",
    "                while '>' in buffer:\n",
    "                    raw, buffer = buffer.split('>', 1)\n",
    "                    record = parse_udp_record(raw + '>')\n",
    "                    if record:\n",
    "                        records.append(record)\n",
    "            except socket.timeout:\n",
    "                break\n",
    "    except Exception as e:\n",
    "        print(f\"Error during UDP read: {e}\")\n",
    "    return records\n",
    "\n",
    "def compute_and_store_median():\n",
    "    global summary_df, current_hour\n",
    "    now = datetime.datetime.now(datetime.timezone.utc).replace(minute=0, second=0, microsecond=0)\n",
    "    if now.hour != current_hour.hour:\n",
    "        # Write accumulated summary\n",
    "        path = ensure_output_path(current_hour)\n",
    "        if not summary_df.is_empty():\n",
    "            if path.exists():\n",
    "                existing = pl.read_parquet(path)\n",
    "                summary_df = pl.concat([existing, summary_df], how=\"diagonal\").unique()\n",
    "            summary_df.write_parquet(path)\n",
    "            print(f\"[{now}] Saved hourly summary: {path}\")\n",
    "        summary_df = pl.DataFrame()\n",
    "        current_hour = now.replace(minute=0, second=0, microsecond=0)\n",
    "\n",
    "    # Collect and compute median\n",
    "    records = read_udp_for_duration(INTERVAL_SECONDS)\n",
    "    if not records:\n",
    "        return\n",
    "\n",
    "    df = pl.DataFrame(records)\n",
    "    value_cols = [col for col in df.columns if col not in {\"id\", \"checksum\"} and df.schema[col] in {pl.Float64, pl.Float32}]\n",
    "    median_row = df.select([pl.median(col).alias(col) for col in value_cols])\n",
    "\n",
    "    median_row = median_row.with_columns([\n",
    "        pl.lit(\"median\").alias(\"id\"),\n",
    "        pl.lit(\"\").alias(\"checksum\"),\n",
    "        pl.lit(now).cast(pl.Datetime(\"us\", \"UTC\")).alias(\"dtm\")\n",
    "    ])\n",
    "    for col in df.columns:\n",
    "        if col not in median_row.columns:\n",
    "            median_row = median_row.with_columns(pl.lit(None).alias(col))\n",
    "\n",
    "    median_row = median_row.select(sorted(median_row.columns))\n",
    "    summary_df = pl.concat([summary_df, median_row], how=\"diagonal\")\n",
    "    print(f\"[{now}] Collected median, running summary count: {len(summary_df)}\")\n",
    "\n",
    "# --- MAIN ---\n",
    "\n",
    "def run_scheduler():\n",
    "    global sock\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as sock_instance:\n",
    "        sock_instance.bind((LOCAL_IP, LOCAL_PORT))\n",
    "        sock = sock_instance  # reference global for reuse\n",
    "        print(f\"Listening on {LOCAL_IP}:{LOCAL_PORT} every {INTERVAL_SECONDS} seconds...\")\n",
    "\n",
    "        schedule.every(INTERVAL_SECONDS).seconds.do(compute_and_store_median)\n",
    "\n",
    "        try:\n",
    "            while True:\n",
    "                schedule.run_pending()\n",
    "                time.sleep(1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Stopped by user.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_scheduler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebe93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import polars as pl\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from typing import Any\n",
    "\n",
    "def parse_udp_record(record: str) -> \"dict[str, Any]\":\n",
    "    try:\n",
    "        id_part, rest = record.split('<', 1)\n",
    "        data_part, checksum = rest.split('>', 1)\n",
    "\n",
    "        parsed = {\"id\": int(id_part.strip()), \"checksum\": checksum.strip()}\n",
    "\n",
    "        if data_part.startswith(\"sendVal\"):\n",
    "            data_part = data_part[len(\"sendVal\"):].strip()\n",
    "\n",
    "        for pair in data_part.split(';'):\n",
    "            if '=' in pair:\n",
    "                k, v = pair.split('=', 1)\n",
    "                key = f\"val_{int(k.strip())}\"\n",
    "                try:\n",
    "                    val = float(v.strip())\n",
    "                except ValueError:\n",
    "                    val = float('nan')\n",
    "                parsed[key] = val\n",
    "\n",
    "        return parsed\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to parse record: {e}\")\n",
    "        return {}\n",
    "\n",
    "def ensure_output_path(base_dir: str, dt: datetime.datetime) -> Path:\n",
    "    y, m, d = dt.year, dt.month, dt.day\n",
    "    folder = Path(base_dir) / f\"{y:04d}\" / f\"{m:02d}\" / f\"{d:02d}\"\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "    filename = f\"fidas-{y:04d}{m:02d}{d:02d}{dt.hour:02d}.parquet\"\n",
    "    return folder / filename\n",
    "\n",
    "def collect_and_log_udp_summary(\n",
    "    base_dir: str,\n",
    "    max_records: int = 100,\n",
    "    local_ip: str = \"0.0.0.0\",\n",
    "    local_port: int = 12345,\n",
    "    buffer_size: int = 1024,\n",
    "    run_minutes: int = 60\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    Collects UDP records, accumulates median summaries over time,\n",
    "    and writes them to hourly .parquet files in a yyyy/mm/dd folder hierarchy.\n",
    "    \"\"\"\n",
    "    sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "    sock.bind((local_ip, local_port))\n",
    "    print(f\"Listening on {local_ip}:{local_port} ...\")\n",
    "\n",
    "    summary_df = pl.DataFrame()\n",
    "    end_time = datetime.datetime.utcnow() + datetime.timedelta(minutes=run_minutes)\n",
    "    buffer = \"\"\n",
    "\n",
    "    try:\n",
    "        while datetime.datetime.utcnow() < end_time:\n",
    "            parsed_records = []\n",
    "            while len(parsed_records) < max_records:\n",
    "                data, _ = sock.recvfrom(buffer_size)\n",
    "                buffer += data.decode('ascii', errors='ignore')\n",
    "\n",
    "                while '>' in buffer and len(parsed_records) < max_records:\n",
    "                    raw_record, buffer = buffer.split('>', 1)\n",
    "                    full_record = raw_record + '>'\n",
    "                    parsed = parse_udp_record(full_record)\n",
    "                    if parsed:\n",
    "                        parsed_records.append(parsed)\n",
    "\n",
    "            if not parsed_records:\n",
    "                continue\n",
    "\n",
    "            df = pl.DataFrame(parsed_records)\n",
    "\n",
    "            # Compute median for value columns\n",
    "            value_cols = [col for col in df.columns if col not in {\"id\", \"checksum\"} and df.schema[col] in {pl.Float64, pl.Float32}]\n",
    "            median_row = df.select([pl.median(col).alias(col) for col in value_cols])\n",
    "\n",
    "            now = datetime.datetime.utcnow()\n",
    "            median_row = median_row.with_columns([\n",
    "                pl.lit(\"median\").alias(\"id\"),\n",
    "                pl.lit(\"\").alias(\"checksum\"),\n",
    "                pl.lit(now).cast(pl.Datetime(\"us\", \"UTC\")).alias(\"dtm\")\n",
    "            ])\n",
    "\n",
    "            for col in df.columns:\n",
    "                if col not in median_row.columns:\n",
    "                    median_row = median_row.with_columns(pl.lit(None).alias(col))\n",
    "\n",
    "            median_row = median_row.select(sorted(median_row.columns))\n",
    "            summary_df = pl.concat([summary_df, median_row], how=\"diagonal\")\n",
    "\n",
    "            # Save to hourly parquet file\n",
    "            out_path = ensure_output_path(base_dir, now)\n",
    "            if out_path.exists():\n",
    "                existing = pl.read_parquet(out_path)\n",
    "                summary_df = pl.concat([existing, summary_df], how=\"vertical\").unique()\n",
    "            summary_df.write_parquet(out_path)\n",
    "            print(f\"Wrote summary to {out_path}\")\n",
    "            summary_df = pl.DataFrame()  # reset for next batch\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Stopped by user.\")\n",
    "    finally:\n",
    "        sock.close()\n",
    "\n",
    "# Run for 60 minutes, saving 100-record summaries to parquet\n",
    "collect_and_log_udp_summary(base_dir=\"data/fidas\", max_records=100, run_minutes=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e250ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import socket\n",
    "import polars as pl\n",
    "from typing import Generator, Any\n",
    "import math\n",
    "\n",
    "UDP_IP = \"192.168.2.129\"  # Listen on all interfaces\n",
    "UDP_PORT = 56790\n",
    "\n",
    "def receive_udp_ascii(\n",
    "    local_ip: str = \"0.0.0.0\",\n",
    "    local_port: int = 12345,\n",
    "    buffer_size: int = 1024\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Receive ASCII data via UDP, accumulating until '>' character marks end of record.\n",
    "\n",
    "    Args:\n",
    "        local_ip: IP address to bind to (use \"0.0.0.0\" for all interfaces).\n",
    "        local_port: UDP port to bind to.\n",
    "        buffer_size: Maximum number of bytes to receive at once.\n",
    "    \"\"\"\n",
    "    with socket.socket(socket.AF_INET, socket.SOCK_DGRAM) as sock:\n",
    "        sock.bind((local_ip, local_port))\n",
    "        sock.settimeout(2)\n",
    "        print(f\"Listening on {local_ip}:{local_port}\")\n",
    "\n",
    "        rcvd = \"\"\n",
    "        try:\n",
    "            while True:\n",
    "                data, addr = sock.recvfrom(buffer_size)\n",
    "                if '>' in data.decode():\n",
    "                    rcvd = f\"{rcvd}{data.decode()}\"\n",
    "                    break\n",
    "\n",
    "            record =\n",
    "\n",
    "            return rcvd\n",
    "        except Exception as err:\n",
    "            print(err)\n",
    "        finally:\n",
    "            sock.close()\n",
    "    # try:\n",
    "    #     while True:\n",
    "    #         data, addr = sock.recvfrom(buffer_size)\n",
    "    #         text = data.decode('ascii', errors='ignore')\n",
    "    #         buffer += text\n",
    "\n",
    "    #         while '>' in buffer:\n",
    "    #             record, buffer = buffer.split('>', 1)\n",
    "    #             record += '>'\n",
    "    #             print(f\"Received from {addr}: {record}\")\n",
    "    #             # You can process the record here\n",
    "\n",
    "    # except KeyboardInterrupt:\n",
    "    #     print(\"\\nStopped by user.\")\n",
    "    # finally:\n",
    "    #     sock.close()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rcvd = receive_udp_ascii(local_ip=UDP_IP, local_port=UDP_PORT))\n",
    "    df = amend\n",
    "\n",
    "# sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\n",
    "# sock.bind((UDP_IP, UDP_PORT))\n",
    "# sock.settimeout(2.0)  # Set timeout to 2 seconds\n",
    "\n",
    "# print(f\"Listening for UDP packets on port {UDP_PORT}...\")\n",
    "\n",
    "# try:\n",
    "#     while True:\n",
    "#         try:\n",
    "#             data, addr = sock.recvfrom(4096)  # buffer size in bytes\n",
    "#             # print(f\"Received from {addr}: {data}\")\n",
    "#             print(data.decode())\n",
    "#         except socket.timeout:\n",
    "#             print(\"Waiting for UDP data...\")\n",
    "# except KeyboardInterrupt:\n",
    "#     print(\"Exiting.\")\n",
    "# finally:\n",
    "#     sock.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c697cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import serial\n",
    "import time\n",
    "\n",
    "# Open COM5 (on Windows) or /dev/ttyS5 (on Linux), adjust accordingly\n",
    "ser = serial.Serial(\n",
    "    port='/dev/ttyUSB0',        # Use '/dev/ttyS5' or '/dev/ttyUSB0' on Linux\n",
    "    baudrate=57600,\n",
    "    bytesize=serial.EIGHTBITS,\n",
    "    parity=serial.PARITY_NONE,\n",
    "    stopbits=serial.STOPBITS_ONE,\n",
    "    timeout=1           # Optional: read timeout in seconds\n",
    ")\n",
    "\n",
    "if ser.is_open:\n",
    "    print(\"Serial port opened successfully.\")\n",
    "\n",
    "# Example write and read (optional)\n",
    "ser.write(b'<getVal 60; 61; 64>')\n",
    "\n",
    "# Optional: wait for device to initialize\n",
    "time.sleep(1)\n",
    "\n",
    "# Loop until data is received\n",
    "print(\"Waiting for data...\")\n",
    "try:\n",
    "    while True:\n",
    "        if ser.in_waiting > 0:\n",
    "            data = ser.read(ser.in_waiting)  # Read all available bytes\n",
    "            print(\"Received:\", data.decode(errors='ignore'))\n",
    "        time.sleep(0.1)  # Avoid busy-waiting\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping.\")\n",
    "\n",
    "# Cleanup\n",
    "ser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
